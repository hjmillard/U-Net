{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa1bc39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hayden\\anaconda3\\envs\\d2l\\lib\\site-packages\\yaml\\__init__.py\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import nbimporter\n",
    "from unet import YouNet, UNet\n",
    "import dataset\n",
    "import utils\n",
    "import PIL\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "import os\n",
    "import numpy as np\n",
    "import yaml\n",
    "print(yaml.__file__)\n",
    "import carvana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81c1769e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "with open(\"config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "NUM_WORKERS = config[\"hyperparams\"][\"NUM_WORKERS\"]\n",
    "BATCH_SIZE = config[\"hyperparams\"][\"BATCH_SIZE\"]\n",
    "NUM_EPOCHS = config[\"hyperparams\"][\"NUM_EPOCHS\"]\n",
    "LEARNING_RATE = float(config[\"hyperparams\"][\"LEARNING_RATE\"])\n",
    "WEIGHT_DECAY = float(config[\"hyperparams\"][\"WEIGHT_DECAY\"])\n",
    "IMAGE_HEIGHT = config[\"hyperparams\"][\"IMAGE_HEIGHT\"]\n",
    "IMAGE_WIDTH = config[\"hyperparams\"][\"IMAGE_WIDTH\"]\n",
    "CROP_SIZE = config[\"hyperparams\"][\"CROP_SIZE\"]\n",
    "\n",
    "device_str = config.get(\"device\", \"auto\")\n",
    "if device_str == \"auto\":\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "else:\n",
    "    DEVICE = torch.device(device_str)\n",
    "    if DEVICE.type == \"cuda\" and not torch.cuda.is_available():\n",
    "        raise RuntimeError(\"CUDA is not available but 'cuda' was specified.\")\n",
    "\n",
    "\n",
    "DATA_DIR = config[\"paths\"][\"DATA_DIR\"]\n",
    "OUTPUT_DIR = config[\"paths\"][\"OUTPUT_DIR\"]\n",
    "WEIGHTS_DIR = config[\"paths\"][\"WEIGHTS_DIR\"]\n",
    "\n",
    "class_weights = np.load(WEIGHTS_DIR)\n",
    "LOSS_WEIGHTS_TENSOR = torch.tensor(class_weights, dtype=torch.float32).to(DEVICE)\n",
    "\n",
    "VOC_COLORMAP = config[\"voc_dataset\"][\"VOC_COLORMAP\"]\n",
    "VOC_CLASSES = config[\"voc_dataset\"][\"VOC_CLASSES\"]\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a57c2850",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, device, image):\n",
    "    with torch.no_grad():\n",
    "        prediction = model(image.to(device)).argmax(1, keepdim=True)\n",
    "    return prediction\n",
    "\n",
    "def prediction_to_image(prediction, device):\n",
    "    VOC_COLORMAP = [[0, 0, 0], [128, 0, 0], [0, 128, 0], [128, 128, 0],\n",
    "                [0, 0, 128], [128, 0, 128], [0, 128, 128], [128, 128, 128],\n",
    "                [64, 0, 0], [192, 0, 0], [64, 128, 0], [192, 128, 0],\n",
    "                [64, 0, 128], [192, 0, 128], [64, 128, 128], [192, 128, 128],\n",
    "                [0, 64, 0], [128, 64, 0], [0, 192, 0], [128, 192, 0],\n",
    "                [0, 64, 128]]\n",
    "    color_map = torch.tensor(VOC_COLORMAP, device=device, dtype=torch.uint8)\n",
    "    X = prediction.squeeze(1).long()\n",
    "    rgb = color_map[X, :].permute(0, 3, 1, 2)\n",
    "    return rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "050d45bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_accuracy(prediction, label):\n",
    "    if len(prediction.shape) > 1 and prediction.shape[1] > 1:\n",
    "        prediction = torch.argmax(prediction, axis=1)\n",
    "    label = label.squeeze(1)\n",
    "    cmp = prediction.type(label.dtype) == label\n",
    "    return float(torch.sum(cmp.type(label.dtype)))\n",
    "\n",
    "def accuracy(prediction, label):\n",
    "    \"\"\"\n",
    "    Example Usage:\n",
    "        a = torch.tensor([1, 2, 3, 4])\n",
    "        b = torch.tensor([1, 0, 3, 5])\n",
    "        accuracy(a, b) -> torch.tensor([1, 0, 1, 0])\n",
    "    \"\"\"\n",
    "    num_matches = (prediction == label).sum().item()\n",
    "    print(num_matches)\n",
    "    return num_matches\n",
    "\n",
    "def compute_accuracy(pred, label):\n",
    "    pred = pred.argmax(1) if pred.dim() > 1 and pred.size(1) > 1 else pred\n",
    "    label = label.squeeze(1) if label.dim() == 4 else label\n",
    "    correct = (pred == label).sum().item()\n",
    "    total = label.numel()\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bf52982",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(loader, model, optimizer, loss_fn, scaler):\n",
    "    model.train()\n",
    "    for batch_i, (X, y) in enumerate(loader):\n",
    "        # print(f'BATCH {batch_i}')\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        X = X.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "\n",
    "        # Forward propagation\n",
    "        # with torch.autocast(device_type=DEVICE, dtype=torch.float16):\n",
    "        # with autocast():\n",
    "        print('X.shape=', X.shape)\n",
    "        y_hat = model(X)\n",
    "        if y.min() < 0 or y.max() >= y_hat.shape[1]:\n",
    "            print(f\"‚ùå Invalid label value in batch: min={y.min().item()}, max={y.max().item()}\")\n",
    "            raise ValueError(\"Label contains out-of-bound class indices.\")\n",
    "        loss = loss_fn(y_hat, y.squeeze(1).long())\n",
    "        \n",
    "        # Backward propagation\n",
    "        # loss.backward()\n",
    "        # optimizer.step()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        train_loss_sum = loss.sum()\n",
    "        train_accuracy_sum = prediction_accuracy(y_hat, y)\n",
    "\n",
    "        return train_loss_sum, train_accuracy_sum\n",
    "\n",
    "        # total_loss += loss.item()\n",
    "        # total_correct += (y_hat.argmax(dim=1) == y).sum().item()\n",
    "        # return total_loss / len(train_loader), total_correct / len(train_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c7ee71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train(model, transforms, batch_size):\n",
    "def train():\n",
    "    model = YouNet(in_channels=3, out_channels=21).to(DEVICE)\n",
    "    # model = UNet(in_channels=3, out_channels=21).to(DEVICE)\n",
    "    train_transform = T.Compose([\n",
    "        T.ToTensor()\n",
    "    ])\n",
    "    validation_transform = T.Compose([\n",
    "        T.ToTensor()\n",
    "    ])\n",
    "    test_transform = T.Compose([\n",
    "        T.ToTensor()\n",
    "    ])\n",
    "    train_loader = dataset.get_data_loader(DATA_DIR, train_transform, train_transform, CROP_SIZE, 'train', BATCH_SIZE)\n",
    "    validation_loader = dataset.get_data_loader(DATA_DIR, train_transform, train_transform, CROP_SIZE, 'val', BATCH_SIZE)\n",
    "    \n",
    "    # Initialize weights\n",
    "    # def init_weights(module):\n",
    "    #     if type(module) in [torch.nn.Linear, torch.nn.Conv2d]:\n",
    "    #         torch.nn.init.normal_(module.weight, std=0.01)\n",
    "    # model.apply(init_weights)\n",
    "\n",
    "    loss_fn = torch.nn.CrossEntropyLoss(ignore_index=0)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    for epoch in range(NUM_EPOCHS+1):\n",
    "        print(f'EPOCH {epoch}:')\n",
    "\n",
    "        model.train()\n",
    "        loss, accuracy = train_batch(train_loader, model, optimizer, loss_fn, scaler)\n",
    "        print(f'Training loss: {loss}')#\\nPrediction accuracy: {accuracy}')\n",
    "\n",
    "        # checkpoint = {\n",
    "        #     'model': model.state_dict(),\n",
    "        #     'optimizer': optimizer.state_dict()\n",
    "        # }\n",
    "        # utils.save_checkpoint(checkpoint)\n",
    "\n",
    "        # TODO: Complete the predictions accuracy function and save predictions to disc.\n",
    "        # predictions accuracy\n",
    "        \n",
    "        val_correct, val_total = 0, 0\n",
    "        with torch.no_grad():\n",
    "                model.eval()\n",
    "                elements = None\n",
    "                for idx, (val_images, val_masks) in enumerate(validation_loader):\n",
    "                    val_images = val_images.to(DEVICE)\n",
    "                    val_masks = val_masks.to(DEVICE)\n",
    "                    \n",
    "                    prediction = predict(model, DEVICE, val_images)\n",
    "                    if elements is None:\n",
    "                        elements = torch.unique(prediction)\n",
    "                    else:\n",
    "                        elements = torch.cat((elements, torch.unique(prediction)), dim=0)\n",
    "\n",
    "                    val_correct += (prediction == val_masks).sum().item()\n",
    "                    val_total += val_masks.numel()\n",
    "                    # valid_acc = prediction_accuracy(prediction, val_masks)\n",
    "                    # print(f'Validation accuracy:  {valid_acc}')\n",
    "\n",
    "\n",
    "                    if epoch % 5 == 0:\n",
    "                        prediction_image = prediction_to_image(prediction, DEVICE)\n",
    "\n",
    "                        image_path = os.path.join(OUTPUT_DIR, f'images_{epoch}')\n",
    "                        if not os.path.exists(image_path):\n",
    "                            os.mkdir(image_path)\n",
    "                        \n",
    "                        for pred_image, val_image, val_mask in zip(prediction_image, val_images, val_masks):\n",
    "                            pred_image = to_pil_image(pred_image.cpu())\n",
    "                            pred_image.save(os.path.join(image_path, f'{idx}_prediction.png'))\n",
    "\n",
    "                            val_image = dataset.denormalize(val_image.cpu())\n",
    "                            val_image = to_pil_image(val_image.cpu())\n",
    "                            val_image.save(os.path.join(image_path, f'{idx}_image.png'))\n",
    "\n",
    "                            val_mask = dataset.mask_to_image(val_mask.cpu(), VOC_COLORMAP)\n",
    "                            val_mask = to_pil_image(val_mask.squeeze(0).cpu())\n",
    "                            val_mask.save(os.path.join(image_path, f'{idx}_mask.png'))\n",
    "                \n",
    "                valid_acc = val_correct / val_total\n",
    "                print(f'Validation accuracy:  {valid_acc}')\n",
    "                print(torch.unique(elements))\n",
    "    # for test_image, test_mask in test_loader:\n",
    "    #     prediction = utils.prediction_to_image(utils.predict(test_loader, model, DEVICE, test_image), DEVICE)\n",
    "    #     test_acc = utils.prediction_accuracy(prediction, test_mask)\n",
    "    #     print(f'Test Accuracy: {test_acc}')\n",
    "\n",
    "        \n",
    "        \n",
    "        # utils.save_predictions(validation_loader, model, data_dir='predictions/', device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "879aa878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_channels=3, out_channels=64\n",
      "in_channels=64, out_channels=128\n",
      "in_channels=128, out_channels=256\n",
      "in_channels=256, out_channels=512\n",
      "in_channels=512, out_channels=1024\n",
      "in_channels=1024, out_channels=512\n",
      "in_channels=512, out_channels=256\n",
      "in_channels=256, out_channels=128\n",
      "in_channels=128, out_channels=64\n",
      "4\n",
      "4\n",
      "EPOCH 0:\n",
      "X.shape= torch.Size([1, 3, 256, 256])\n",
      "Training loss: 3.0390970706939697\n",
      "Validation accuracy:  0.000659942626953125\n",
      "tensor([1, 3, 6, 7], device='cuda:0')\n",
      "EPOCH 1:\n",
      "X.shape= torch.Size([1, 3, 256, 256])\n",
      "Training loss: 3.0381815433502197\n",
      "Validation accuracy:  0.0341644287109375\n",
      "tensor([1, 3, 6, 7], device='cuda:0')\n",
      "EPOCH 2:\n",
      "X.shape= torch.Size([1, 3, 256, 256])\n",
      "Training loss: 3.037264585494995\n",
      "Validation accuracy:  0.08246612548828125\n",
      "tensor([1, 3, 7], device='cuda:0')\n",
      "EPOCH 3:\n",
      "X.shape= torch.Size([1, 3, 256, 256])\n",
      "Training loss: 3.036228656768799\n",
      "Validation accuracy:  0.07462692260742188\n",
      "tensor([1, 3], device='cuda:0')\n",
      "EPOCH 4:\n",
      "X.shape= torch.Size([1, 3, 256, 256])\n",
      "Training loss: 3.0352351665496826\n",
      "Validation accuracy:  0.09497451782226562\n",
      "tensor([1, 3], device='cuda:0')\n",
      "EPOCH 5:\n",
      "X.shape= torch.Size([1, 3, 256, 256])\n",
      "Training loss: 3.0340821743011475\n",
      "Validation accuracy:  0.09508895874023438\n",
      "tensor([1, 3], device='cuda:0')\n",
      "EPOCH 6:\n",
      "X.shape= torch.Size([1, 3, 256, 256])\n",
      "Training loss: 3.0327987670898438\n",
      "Validation accuracy:  0.04784393310546875\n",
      "tensor([1, 3], device='cuda:0')\n",
      "EPOCH 7:\n",
      "X.shape= torch.Size([1, 3, 256, 256])\n",
      "Training loss: 3.031205415725708\n",
      "Validation accuracy:  0.08511734008789062\n",
      "tensor([1, 3], device='cuda:0')\n",
      "EPOCH 8:\n",
      "X.shape= torch.Size([1, 3, 256, 256])\n",
      "Training loss: 3.0293757915496826\n",
      "Validation accuracy:  0.07218170166015625\n",
      "tensor([1, 3], device='cuda:0')\n",
      "EPOCH 9:\n",
      "X.shape= torch.Size([1, 3, 256, 256])\n",
      "Training loss: 3.027806043624878\n",
      "Validation accuracy:  0.0660552978515625\n",
      "tensor([1, 3], device='cuda:0')\n",
      "EPOCH 10:\n",
      "X.shape= torch.Size([1, 3, 256, 256])\n",
      "Training loss: 3.0250935554504395\n",
      "Validation accuracy:  0.058803558349609375\n",
      "tensor([1, 3], device='cuda:0')\n",
      "EPOCH 11:\n",
      "X.shape= torch.Size([1, 3, 256, 256])\n",
      "Training loss: 3.0221002101898193\n",
      "Validation accuracy:  0.09881591796875\n",
      "tensor([1, 3], device='cuda:0')\n",
      "EPOCH 12:\n",
      "X.shape= torch.Size([1, 3, 256, 256])\n",
      "Training loss: 3.0199320316314697\n",
      "Validation accuracy:  0.07018661499023438\n",
      "tensor([1, 3], device='cuda:0')\n",
      "EPOCH 13:\n",
      "X.shape= torch.Size([1, 3, 256, 256])\n",
      "Training loss: 3.014963150024414\n",
      "Validation accuracy:  0.049991607666015625\n",
      "tensor([1], device='cuda:0')\n",
      "EPOCH 14:\n",
      "X.shape= torch.Size([1, 3, 256, 256])\n",
      "Training loss: 3.009885311126709\n",
      "Validation accuracy:  0.0833892822265625\n",
      "tensor([1], device='cuda:0')\n",
      "EPOCH 15:\n",
      "X.shape= torch.Size([1, 3, 256, 256])\n",
      "Training loss: 3.0031352043151855\n",
      "Validation accuracy:  0.045658111572265625\n",
      "tensor([1], device='cuda:0')\n",
      "EPOCH 16:\n",
      "X.shape= torch.Size([1, 3, 256, 256])\n",
      "Training loss: 2.9967777729034424\n",
      "Validation accuracy:  0.052982330322265625\n",
      "tensor([1], device='cuda:0')\n",
      "EPOCH 17:\n",
      "X.shape= torch.Size([1, 3, 256, 256])\n",
      "Training loss: 2.983761787414551\n",
      "Validation accuracy:  0.0508575439453125\n",
      "tensor([1], device='cuda:0')\n",
      "EPOCH 18:\n",
      "X.shape= torch.Size([1, 3, 256, 256])\n",
      "Training loss: 2.9736363887786865\n",
      "Validation accuracy:  0.054813385009765625\n",
      "tensor([1], device='cuda:0')\n",
      "EPOCH 19:\n",
      "X.shape= torch.Size([1, 3, 256, 256])\n",
      "Training loss: 2.945378065109253\n",
      "Validation accuracy:  0.09894180297851562\n",
      "tensor([1], device='cuda:0')\n",
      "EPOCH 20:\n",
      "X.shape= torch.Size([1, 3, 256, 256])\n",
      "Training loss: 2.9198615550994873\n",
      "Validation accuracy:  0.0871429443359375\n",
      "tensor([1], device='cuda:0')\n",
      "EPOCH 21:\n",
      "X.shape= torch.Size([1, 3, 256, 256])\n",
      "Training loss: 2.866229295730591\n",
      "Validation accuracy:  0.09624862670898438\n",
      "tensor([1], device='cuda:0')\n",
      "EPOCH 22:\n",
      "X.shape= torch.Size([1, 3, 256, 256])\n",
      "Training loss: 2.743685722351074\n",
      "Validation accuracy:  0.09818649291992188\n",
      "tensor([1], device='cuda:0')\n",
      "EPOCH 23:\n",
      "X.shape= torch.Size([1, 3, 256, 256])\n",
      "Training loss: 2.5740013122558594\n",
      "Validation accuracy:  0.09597015380859375\n",
      "tensor([1], device='cuda:0')\n",
      "EPOCH 24:\n",
      "X.shape= torch.Size([1, 3, 256, 256])\n",
      "Training loss: 2.291353225708008\n",
      "Validation accuracy:  0.0513763427734375\n",
      "tensor([1], device='cuda:0')\n",
      "EPOCH 25:\n",
      "X.shape= torch.Size([1, 3, 256, 256])\n",
      "Training loss: 2.1433393955230713\n",
      "Validation accuracy:  0.09614181518554688\n",
      "tensor([1], device='cuda:0')\n",
      "EPOCH 26:\n",
      "X.shape= torch.Size([1, 3, 256, 256])\n",
      "Training loss: 2.125303030014038\n",
      "Validation accuracy:  0.044857025146484375\n",
      "tensor([1], device='cuda:0')\n",
      "EPOCH 27:\n",
      "X.shape= torch.Size([1, 3, 256, 256])\n",
      "Training loss: 2.123244285583496\n",
      "Validation accuracy:  0.06324386596679688\n",
      "tensor([1], device='cuda:0')\n",
      "EPOCH 28:\n",
      "X.shape= torch.Size([1, 3, 256, 256])\n",
      "Training loss: 2.123169422149658\n",
      "Validation accuracy:  0.07951736450195312\n",
      "tensor([1], device='cuda:0')\n",
      "EPOCH 29:\n",
      "X.shape= torch.Size([1, 3, 256, 256])\n",
      "Training loss: 2.123169422149658\n",
      "Validation accuracy:  0.09587860107421875\n",
      "tensor([1], device='cuda:0')\n",
      "EPOCH 30:\n",
      "X.shape= torch.Size([1, 3, 256, 256])\n",
      "Training loss: 2.123169422149658\n",
      "Validation accuracy:  0.0662689208984375\n",
      "tensor([1], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
