{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "660e1e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import os\n",
    "import nbimporter\n",
    "from dataset import VocDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a96d7e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loaders(data_dir, train_transforms, validation_transforms, test_transforms, batch_size):\n",
    "    train_loader = DataLoader(\n",
    "        VocDataset(data_dir, train_transforms, 'train'),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "        num_workers=0\n",
    "    )\n",
    "    validation_loader = DataLoader(\n",
    "        VocDataset(data_dir, validation_transforms, 'val'),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        drop_last=True,\n",
    "        num_workers=0\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        VocDataset(data_dir, test_transforms, 'test'),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "        num_workers=0\n",
    "    )\n",
    "    return train_loader, validation_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e2ccaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOC_COLORMAP = [[0, 0, 0], [128, 0, 0], [0, 128, 0], [128, 128, 0],\n",
    "                [0, 0, 128], [128, 0, 128], [0, 128, 128], [128, 128, 128],\n",
    "                [64, 0, 0], [192, 0, 0], [64, 128, 0], [192, 128, 0],\n",
    "                [64, 0, 128], [192, 0, 128], [64, 128, 128], [192, 128, 128],\n",
    "                [0, 64, 0], [128, 64, 0], [0, 192, 0], [128, 192, 0],\n",
    "                [0, 64, 128]]\n",
    "\n",
    "VOC_CLASSES = ['background', 'aeroplane', 'bicycle', 'bird', 'boat',\n",
    "               'bottle', 'bus', 'car', 'cat', 'chair', 'cow',\n",
    "               'diningtable', 'dog', 'horse', 'motorbike', 'person',\n",
    "               'potted plant', 'sheep', 'sofa', 'train', 'tv/monitor']\n",
    "\n",
    "\n",
    "def predict(test_iterator, model, device, image):\n",
    "    # test iterator is from DataLoader for test set.\n",
    "    # X = test_iterator.dataset.normalize(image).unsqueeze(0)\n",
    "    X = test_iterator.dataset.normalize(image)\n",
    "    print(f'X.shape={X.shape}')\n",
    "    with torch.no_grad():\n",
    "        prediction = model(X.to(device)).argmax(dim=1)\n",
    "    # return prediction.reshape(prediction.shape[1], prediction.shape[2])\n",
    "    print(f'prediction.unsqueeze(0).shape={prediction.unsqueeze(0).shape}')\n",
    "    return prediction.unsqueeze(0)\n",
    "\n",
    "def prediction_to_image(prediction, device):\n",
    "    VOC_COLORMAP = [[0, 0, 0], [128, 0, 0], [0, 128, 0], [128, 128, 0],\n",
    "                [0, 0, 128], [128, 0, 128], [0, 128, 128], [128, 128, 128],\n",
    "                [64, 0, 0], [192, 0, 0], [64, 128, 0], [192, 128, 0],\n",
    "                [64, 0, 128], [192, 0, 128], [64, 128, 128], [192, 128, 128],\n",
    "                [0, 64, 0], [128, 64, 0], [0, 192, 0], [128, 192, 0],\n",
    "                [0, 64, 128]]\n",
    "    color_map = torch.tensor(VOC_COLORMAP, device=device)\n",
    "    print(f'PREDICTION_TO_IMAGE: color_map={color_map.shape} prediction={prediction.shape}')\n",
    "    X = prediction.long()\n",
    "    print(f'PREDICTION_TO_IMAGE: color_map={color_map.shape} prediction.long={X.shape}')\n",
    "    print(f'color_map[X, :]={color_map[X, :].shape}')\n",
    "    return color_map[X, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be333cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def prediction_accuracy(prediction, label):\n",
    "    print(f'PREDICTION_ACCURACY: prediction={prediction.shape} label={label.shape}')\n",
    "    print(f'PREDICTION: \\n{prediction}')\n",
    "    print(f'LABEL: \\n{label}')\n",
    "    if len(prediction.shape) > 1 and prediction.shape[1] > 1:\n",
    "        prediction = torch.argmax(prediction, axis=1)\n",
    "    cmp = prediction.type(label.dtype) == label\n",
    "    return float(torch.sum(cmp.type(label.dtype)))\n",
    "\n",
    "def accuracy(prediction, label):\n",
    "    num_matches = (prediction == label).sum().item()\n",
    "    print(num_matches)\n",
    "\n",
    "a = torch.tensor([1, 2, 3, 4])\n",
    "b = torch.tensor([1, 0, 3, 5])\n",
    "accuracy(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4eb22535",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state_dict, checkpoint_file='model/model.pt'):\n",
    "    '''Saves the model state to disc.'''\n",
    "    # if not os.path.exists(checkpoint_file):\n",
    "    #     print(f'Error. The path {checkpoint_file} does not exist. Could not save model state.')\n",
    "    torch.save(state_dict, checkpoint_file)\n",
    "\n",
    "def load_checkpoint(model, checkpoint_file='model/model.pt'):\n",
    "    '''Loads the model state from disc.'''\n",
    "    if not os.path.exists(checkpoint_file):\n",
    "        print(f'Error. The path {checkpoint_file} does not exist. Could not retreive model state.')\n",
    "    model.load_state_dict(checkpoint_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2ce324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO: complete the function to save prediction images to the predictions/ directory\n",
    "\n",
    "# def save_predictions(loader, model, folder='predictions/', device='cuda'):\n",
    "#     for index, (feature, label) in enumerate(loader):\n",
    "#         feature = feature.to(device)\n",
    "#         with torch.no_grad():\n",
    "#             predictions = label_to_image(predict(model(feature)))\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
